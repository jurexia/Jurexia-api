#!/usr/bin/env python3
"""
terminator_leyes.py ‚Äî Terminator para Leyes Estatales Mexicanas

Limpia y estructura el texto extra√≠do de PDFs de leyes estatales.
Produce art√≠culos completos con texto limpio y jerarqu√≠a preservada.

Pipeline:
  1. limpieza_headers()       ‚Üí Remueve basura de headers/footers de legislaturas
  2. costura_inteligente()    ‚Üí Une l√≠neas cortadas por columnas del PDF
  3. split_por_articulos()    ‚Üí Separa en art√≠culos completos
  4. enriquecer_jerarquia()   ‚Üí Extrae T√≠tulo, Cap√≠tulo, Secci√≥n del contexto
  5. validar_articulo()       ‚Üí Verifica integridad del art√≠culo

Uso:
    from terminator_leyes import procesar_ley
    articulos = procesar_ley(texto_raw, nombre_ley)
"""

import re
from dataclasses import dataclass, field
from typing import Optional


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# CONFIGURATION
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

MIN_ARTICLE_LEN = 40         # M√≠nimo de caracteres para un art√≠culo v√°lido
MAX_CHUNK_CHARS = 5000       # M√°ximo por chunk (~1250 tokens)
OVERLAP_CHARS = 400          # Overlap para art√≠culos largos


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# DATA CLASSES
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

@dataclass
class ArticuloLimpio:
    """Un art√≠culo procesado y limpio, listo para embedding."""
    texto: str                    # Texto completo y limpio del art√≠culo
    ref: str                      # "Art. 15", "Art. 15 Bis", "Transitorios"
    origen: str                   # Nombre completo de la ley
    titulo: str = ""              # "T√çTULO PRIMERO" (jerarqu√≠a)
    capitulo: str = ""            # "CAP√çTULO II" (jerarqu√≠a)
    seccion: str = ""             # "SECCI√ìN TERCERA" (jerarqu√≠a)
    jerarquia_txt: str = ""       # "Ley X > T√≠tulo I > Cap. II > Art. 15"
    chunk_index: int = 0          # Sub-chunk para art√≠culos largos
    es_transitorio: bool = False  # Art√≠culos transitorios


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# PASO 1: LIMPIEZA DE HEADERS/FOOTERS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# Patrones de basura comunes en PDFs de legislaturas estatales
_BASURA_PATTERNS = [
    # Headers de p√°ginas de legislaturas
    r'Peri√≥dico\s+Oficial\s+"?La\s+Sombra\s+de\s+Arteaga"?',
    r'PERI√ìDICO\s+OFICIAL\s+DEL?\s+GOBIERNO',
    r'Gaceta\s+Oficial\s+del?\s+',
    r'Gaceta\s+Parlamentaria',
    r'DIARIO\s+OFICIAL',
    r'La\s+Sombra\s+de\s+Arteaga',
    
    # Paginaci√≥n
    r'P√°g(?:ina)?\.?\s*\d+\s*(?:de\s*\d+)?',
    r'P√°gina\s*\d+\s*de\s*\d+',
    r'[-‚Äì‚Äî]\s*\d+\s*[-‚Äì‚Äî]',                  # ‚Äî 15 ‚Äî
    r'^\s*\d+\s*$',                           # N√∫meros sueltos (no art√≠culos)
    
    # Fechas de publicaci√≥n (en headers)
    r'\d{1,2}\s+de\s+(?:enero|febrero|marzo|abril|mayo|junio|julio|agosto|'
    r'septiembre|octubre|noviembre|diciembre)\s+de\s+\d{4}',
    
    # URLs y marcas web
    r'https?://\S+',
    r'www\.\S+',
    
    # Headers repetitivos de legislaturas
    r'(?:LX|LI|LII|LIII|LIV|LV|LVI|LVII|LVIII|LIX|LXI|LXII|LXIII|LXIV|LXV)\s*LEGISLATURA',
    r'H\.\s*CONGRESO\s+DEL\s+ESTADO',
    r'PODER\s+LEGISLATIVO\s+DEL\s+ESTADO',
    
    # Marcas de agua y sellos
    r'√öLTIMA\s+REFORMA\s+PUBLICADA\s+EN\s+EL\s+P\.?\s*O\.?',
    r'Fe\s+de\s+erratas?\s+(?:publicada|DOF)',
    r'Nota\s+de\s+Editor:.*',
]

_BASURA_COMPILED = [re.compile(p, re.IGNORECASE | re.MULTILINE) for p in _BASURA_PATTERNS]


def limpieza_headers(texto: str) -> str:
    """
    Elimina headers, footers, y basura intrusiva de PDFs de legislaturas.
    Preserva la estructura del contenido legal.
    """
    for pattern in _BASURA_COMPILED:
        texto = pattern.sub(' ', texto)
    
    # Colapsar whitespace excesivo
    texto = re.sub(r'\n{3,}', '\n\n', texto)
    texto = re.sub(r'[ \t]{2,}', ' ', texto)
    
    return texto.strip()


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# PASO 2: COSTURA INTELIGENTE
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def costura_inteligente(texto: str) -> str:
    """
    Une l√≠neas cortadas por el formato de columnas del PDF.
    
    Problema: Los PDFs de legislaturas cortan l√≠neas por ancho de columna,
    produciendo oraciones fragmentadas:
        "Los ciudadanos que come-"
        "tan infracciones ser√°n"
    
    Soluci√≥n: Unir l√≠neas que no terminan en puntuaci√≥n, respetando
    los l√≠mites de art√≠culos, incisos y fracciones.
    """
    # 1. Unir palabras con gui√≥n al final de l√≠nea (hifenaci√≥n)
    texto = re.sub(r'(\w+)-\s*\n\s*(\w+)', r'\1\2', texto)
    
    # 2. Unir l√≠neas que no terminan en puntuaci√≥n terminal
    # PERO respetar:
    #   - Art√≠culos (Art√≠culo N.)
    #   - Fracciones (I., II., III., etc.)
    #   - Incisos (a), b), c), etc.)
    #   - Numerales (1., 2., 3., etc.)
    #   - T√≠tulos/Cap√≠tulos en MAY√öSCULAS
    texto = re.sub(
        r'(?<![\.;:!?\)])\n'              # L√≠nea NO termina en puntuaci√≥n
        r'(?!\s*(?:'                        # La siguiente l√≠nea NO empieza con:
        r'Art[i√≠]culo\s+'                   #   Art√≠culo
        r'|[IVX]+\.\s'                      #   Fracciones romanas (I., II., etc.)
        r'|[a-z]\)\s'                       #   Incisos (a), b), etc.)
        r'|\d+\.\s'                         #   Numerales (1., 2., etc.)
        r'|T√çTULO\s'                        #   T√≠tulos
        r'|CAPITULO\s|CAP√çTULO\s'           #   Cap√≠tulos
        r'|SECCI√ìN\s|SECCION\s'             #   Secciones
        r'|LIBRO\s'                         #   Libros
        r'|TRANSITORI'                      #   Transitorios
        r'))',
        ' ',
        texto,
        flags=re.IGNORECASE
    )
    
    # 3. Limpiar espacios m√∫ltiples (pero NO eliminar \n\n que son p√°rrafos)
    texto = re.sub(r'[ \t]{2,}', ' ', texto)
    texto = re.sub(r' +\.', '.', texto)
    
    return texto.strip()


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# PASO 3: SPLIT POR ART√çCULOS
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

# Regex para detectar el inicio de un art√≠culo
_ART_BOUNDARY = re.compile(
    r'(?:^|\n)\s*'                                      # Inicio de l√≠nea
    r'(Art[i√≠]culo\s+\d+[\w]*'                          # "Art√≠culo 15", "Art√≠culo 15A"
    r'(?:\s+(?:BIS|TER|QU√ÅTER|QUATER|QUINQUIES))?'     # Sufijos opcionales
    r')\s*[\.\-\s]',                                     # Seguido de per√≠odo, gui√≥n o espacio
    re.IGNORECASE | re.MULTILINE
)

# Regex para extraer la referencia de un art√≠culo
_ART_REF = re.compile(
    r'Art[i√≠]culo\s+(\d+[\w]*(?:\s+(?:BIS|TER|QU√ÅTER|QUATER|QUINQUIES))?)',
    re.IGNORECASE
)

# Regex para detectar Transitorios
_TRANSITORIOS = re.compile(
    r'(?:^|\n)\s*(TRANSITORIOS?)\s*\n',
    re.IGNORECASE | re.MULTILINE
)

# Regex para detectar encabezados de estructura
_TITULO = re.compile(
    r'(?:^|\n)\s*(T√çTULO\s+[IVXLCDM\d]+(?:\s+[A-Z√Å√â√ç√ì√ö√ë,\s]+)?)',
    re.IGNORECASE | re.MULTILINE
)
_CAPITULO = re.compile(
    r'(?:^|\n)\s*(CAP[√çI]TULO\s+[IVXLCDM\d]+(?:\s+[A-Z√Å√â√ç√ì√ö√ë,\s]+)?)',
    re.IGNORECASE | re.MULTILINE
)
_SECCION = re.compile(
    r'(?:^|\n)\s*(SECCI[√ìO]N\s+[IVXLCDM\d]+(?:\s+[A-Z√Å√â√ç√ì√ö√ë,\s]+)?)',
    re.IGNORECASE | re.MULTILINE
)


def _extraer_jerarquia(texto_previo: str, titulo_actual: str, 
                        capitulo_actual: str, seccion_actual: str):
    """
    Extrae la jerarqu√≠a actual (T√≠tulo, Cap√≠tulo, Secci√≥n) del texto
    que precede a un art√≠culo.
    """
    # Buscar el √∫ltimo T√≠tulo, Cap√≠tulo y Secci√≥n en el texto previo
    for m in _TITULO.finditer(texto_previo):
        titulo_actual = m.group(1).strip()
        capitulo_actual = ""      # Reset cap√≠tulo al cambiar de t√≠tulo
        seccion_actual = ""       # Reset secci√≥n al cambiar de t√≠tulo
    
    for m in _CAPITULO.finditer(texto_previo):
        capitulo_actual = m.group(1).strip()
        seccion_actual = ""       # Reset secci√≥n al cambiar de cap√≠tulo
    
    for m in _SECCION.finditer(texto_previo):
        seccion_actual = m.group(1).strip()
    
    return titulo_actual, capitulo_actual, seccion_actual


def _construir_jerarquia_txt(origen: str, titulo: str, capitulo: str, 
                              seccion: str, ref: str) -> str:
    """Construye la cadena de jerarqu√≠a textual."""
    parts = [origen]
    if titulo:
        parts.append(titulo)
    if capitulo:
        parts.append(capitulo)
    if seccion:
        parts.append(seccion)
    parts.append(ref)
    return " > ".join(parts)


def split_por_articulos(texto: str, origen: str) -> list[ArticuloLimpio]:
    """
    Separa el texto limpio en art√≠culos individuales completos.
    
    Estrategia:
    1. Detecta boundaries de art√≠culos usando regex
    2. Cada art√≠culo incluye todo el texto hasta el siguiente art√≠culo
    3. Preserva la jerarqu√≠a (T√≠tulo, Cap√≠tulo, Secci√≥n) por contexto
    4. Los art√≠culos largos se sub-dividen con overlap
    5. Pre√°mbulo y Transitorios se manejan como chunks especiales
    """
    if not texto.strip():
        return []
    
    articulos: list[ArticuloLimpio] = []
    
    # Encontrar todas las posiciones de art√≠culos
    matches = list(_ART_BOUNDARY.finditer(texto))
    
    if not matches:
        # No hay art√≠culos detectados ‚Üí chunk como texto fijo
        return _chunk_texto_fijo(texto, origen, "Secci√≥n General")
    
    # Estado de jerarqu√≠a
    titulo_actual = ""
    capitulo_actual = ""
    seccion_actual = ""
    
    # Procesar pre√°mbulo (texto antes del primer art√≠culo)
    preambulo = texto[:matches[0].start()].strip()
    if preambulo and len(preambulo) > MIN_ARTICLE_LEN:
        # Extraer jerarqu√≠a del pre√°mbulo
        titulo_actual, capitulo_actual, seccion_actual = _extraer_jerarquia(
            preambulo, titulo_actual, capitulo_actual, seccion_actual
        )
        articulos.extend(_chunk_texto_fijo(preambulo, origen, "Pre√°mbulo"))
    
    # Procesar cada art√≠culo
    for idx, match in enumerate(matches):
        # Texto del art√≠culo = desde este match hasta el siguiente (o fin del texto)
        art_start = match.start()
        if idx + 1 < len(matches):
            art_end = matches[idx + 1].start()
        else:
            art_end = len(texto)
        
        art_text = texto[art_start:art_end].strip()
        
        if len(art_text) < MIN_ARTICLE_LEN:
            continue
        
        # Extraer referencia del art√≠culo
        ref_match = _ART_REF.search(match.group(1))
        ref = f"Art. {ref_match.group(1)}" if ref_match else match.group(1).strip()[:30]
        
        # Actualizar jerarqu√≠a basada en el texto previo
        # (Headers de T√≠tulo/Cap√≠tulo/Secci√≥n que estaban ANTES de este art√≠culo)
        titulo_actual, capitulo_actual, seccion_actual = _extraer_jerarquia(
            art_text, titulo_actual, capitulo_actual, seccion_actual
        )
        
        jerarquia = _construir_jerarquia_txt(
            origen, titulo_actual, capitulo_actual, seccion_actual, ref
        )
        
        # Verificar si hay Transitorios en este art√≠culo (para el √∫ltimo)
        trans_match = _TRANSITORIOS.search(art_text)
        if trans_match and idx == len(matches) - 1:
            # Separar contenido del art√≠culo y transitorios
            art_only = art_text[:trans_match.start()].strip()
            trans_text = art_text[trans_match.start():].strip()
            
            if art_only and len(art_only) >= MIN_ARTICLE_LEN:
                articulos.extend(_chunk_articulo(
                    art_only, ref, origen, titulo_actual, 
                    capitulo_actual, seccion_actual, jerarquia
                ))
            
            if trans_text and len(trans_text) >= MIN_ARTICLE_LEN:
                trans_jer = _construir_jerarquia_txt(
                    origen, "", "", "", "Transitorios"
                )
                articulos.extend(_chunk_articulo(
                    trans_text, "Transitorios", origen, 
                    "", "", "", trans_jer, es_transitorio=True
                ))
            continue
        
        # Chunk normal del art√≠culo
        articulos.extend(_chunk_articulo(
            art_text, ref, origen, titulo_actual, 
            capitulo_actual, seccion_actual, jerarquia
        ))
    
    return articulos


def _chunk_articulo(texto: str, ref: str, origen: str, 
                     titulo: str, capitulo: str, seccion: str,
                     jerarquia: str, es_transitorio: bool = False) -> list[ArticuloLimpio]:
    """
    Convierte un art√≠culo en uno o m√°s chunks.
    Si el art√≠culo excede MAX_CHUNK_CHARS, lo subdivide con overlap.
    """
    if len(texto) <= MAX_CHUNK_CHARS:
        return [ArticuloLimpio(
            texto=texto,
            ref=ref,
            origen=origen,
            titulo=titulo,
            capitulo=capitulo,
            seccion=seccion,
            jerarquia_txt=jerarquia,
            chunk_index=0,
            es_transitorio=es_transitorio,
        )]
    
    # Subdividir art√≠culos largos
    parts = _split_long_text(texto)
    return [
        ArticuloLimpio(
            texto=part,
            ref=ref,
            origen=origen,
            titulo=titulo,
            capitulo=capitulo,
            seccion=seccion,
            jerarquia_txt=jerarquia,
            chunk_index=i,
            es_transitorio=es_transitorio,
        )
        for i, part in enumerate(parts)
    ]


def _chunk_texto_fijo(texto: str, origen: str, ref: str) -> list[ArticuloLimpio]:
    """Chunk fallback para texto sin art√≠culos (pre√°mbulos, exposiciones de motivos)."""
    parts = _split_long_text(texto, max_chars=3500)
    return [
        ArticuloLimpio(
            texto=part.strip(),
            ref=ref if len(parts) == 1 else f"{ref} ({i+1})",
            origen=origen,
            jerarquia_txt=f"{origen} > {ref}",
            chunk_index=i,
        )
        for i, part in enumerate(parts) if len(part.strip()) >= MIN_ARTICLE_LEN
    ]


def _split_long_text(texto: str, max_chars: int = MAX_CHUNK_CHARS) -> list[str]:
    """Subdivide texto largo en partes con overlap, priorizando cortes en p√°rrafos."""
    if len(texto) <= max_chars:
        return [texto]
    
    parts = []
    start = 0
    while start < len(texto):
        end = start + max_chars
        if end >= len(texto):
            parts.append(texto[start:])
            break
        
        # Buscar el mejor punto de corte (prioridad: p√°rrafo > oraci√≥n > palabra)
        split_point = texto.rfind('\n\n', start + max_chars // 2, end)
        if split_point == -1:
            split_point = texto.rfind('. ', start + max_chars // 2, end)
        if split_point == -1:
            split_point = texto.rfind(' ', start + max_chars // 2, end)
        if split_point == -1:
            split_point = end
        else:
            split_point += 1  # Incluir delimitador
        
        parts.append(texto[start:split_point])
        start = split_point - OVERLAP_CHARS  # Overlap
    
    return parts


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# PASO 4: PIPELINE COMPLETO
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def procesar_ley(texto_raw: str, nombre_ley: str) -> list[ArticuloLimpio]:
    """
    Pipeline completo: texto crudo de PDF ‚Üí art√≠culos limpios.
    
    Args:
        texto_raw: Texto extra√≠do del PDF (sin procesar)
        nombre_ley: Nombre oficial de la ley
    
    Returns:
        Lista de ArticuloLimpio listos para embedding
    """
    # Normalizar line endings
    texto = texto_raw.replace('\r\n', '\n').replace('\r', '\n')
    
    # Paso 1: Limpiar headers/footers
    texto = limpieza_headers(texto)
    
    # Paso 2: Costura inteligente (unir l√≠neas quebradas)
    texto = costura_inteligente(texto)
    
    # Paso 3: Split por art√≠culos
    articulos = split_por_articulos(texto, nombre_ley)
    
    return articulos


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# DIAGN√ìSTICO (para testing)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def diagnostico(articulos: list[ArticuloLimpio]) -> dict:
    """Genera estad√≠sticas de los art√≠culos procesados."""
    if not articulos:
        return {"total": 0}
    
    lens = [len(a.texto) for a in articulos]
    refs = set(a.ref for a in articulos)
    transitorios = sum(1 for a in articulos if a.es_transitorio)
    
    return {
        "total": len(articulos),
        "articulos_unicos": len(refs),
        "transitorios": transitorios,
        "chars_min": min(lens),
        "chars_max": max(lens),
        "chars_avg": sum(lens) // len(lens),
        "con_jerarquia": sum(1 for a in articulos if a.titulo),
    }


if __name__ == "__main__":
    # Quick test with a sample
    sample = """
    T√çTULO PRIMERO
    DISPOSICIONES GENERALES
    
    CAP√çTULO I
    DEL OBJETO Y DEFINICIONES
    
    Art√≠culo 1. La presente Ley es de orden p√∫blico e inter√©s social y tiene por 
    objeto regular las relaciones entre los particulares y el Estado en materia de
    infracciones c√≠vicas.
    
    Art√≠culo 2. Para los efectos de la presen-
    te Ley, se entender√° por:
    I. Autoridad: Los servidores p√∫blicos;
    II. Infracci√≥n: Toda conducta que atente contra el orden p√∫blico;
    III. Sanci√≥n: La multa o arresto impuestos.
    
    CAP√çTULO II
    DE LAS INFRACCIONES
    
    Art√≠culo 3. Son faltas c√≠vicas las siguientes conductas:
    a) Orinar o defecar en la v√≠a p√∫blica;
    b) Consumir bebidas alcoh√≥licas en la v√≠a p√∫blica;
    c) Alterar el orden p√∫blico con ruidos excesivos.
    
    Art√≠culo 4. Las sanciones por las infracciones previstas en el art√≠culo anterior
    ser√°n de 11 a 20 veces la Unidad de Medida y Actualizaci√≥n vigente.
    
    TRANSITORIOS
    
    PRIMERO. La presente Ley entrar√° en vigor al d√≠a siguiente de su publicaci√≥n.
    SEGUNDO. Se derogan todas las disposiciones que se opongan a esta Ley.
    """
    
    articulos = procesar_ley(sample, "Ley de Cultura C√≠vica de Quer√©taro")
    stats = diagnostico(articulos)
    print(f"\nüìä DIAGN√ìSTICO:")
    for k, v in stats.items():
        print(f"   {k}: {v}")
    
    print(f"\nüìÑ ART√çCULOS:")
    for a in articulos:
        preview = a.texto[:100].replace('\n', ' ')
        print(f"   [{a.ref}] ({len(a.texto)} chars) {a.jerarquia_txt}")
        print(f"      {preview}...")
